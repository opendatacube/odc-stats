name: Publish to S3 and PyPI

on:
  workflow_run:
    workflows: ["Run Code Checks"]
    branches: [develop]
    types:
      - completed

jobs:
  bump_version:
    if: |
        github.repository == 'opendatacube/odc-stats'
        && github.event.workflow_run.conclusion == 'success'

    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Setup Python
        uses: actions/setup-python@v1
        with:
          python-version: 3.8

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install --upgrade setuptools
          python -m pip install --upgrade packaging
          python -m pip freeze

      - name: Verify Changed files
        uses: tj-actions/changed-files@v32
        id: verify-changed-version
        with:
          files: |
              odc/**
              pyproject.toml
              setup.py
              setup.cfg

      - name: Patch Package Versions when code change.
        if: steps.verify-changed-version.outputs.any_changed == 'true'
        id: patch-version
        run: |
          # -1: auto increment of patch number
          # other positive integers: set the patch number accordingly
          python ./scripts/patch_version.py -1 ./odc/stats/_version.py
          echo "TAG=$(cat dummy/_version.py  | sed 's/[^0-9|.]//g')" \
            >> $GITHUB_OUTPUT

      - name: Push and tag versions
        if: steps.patch-version.outcome == 'success'
        id: push-new-tag
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_ACTOR: autoaction
        run: |
          git config --global user.email "$GITHUB_ACTOR@auto.noreply"
          git config --global user.name "$GITHUB_ACTOR"
          git commit -a -m \
            "Bump version to ${{ steps.patch-version.outputs.TAG }}"
          git push origin --follow-tags
          git tag ${{ steps.patch-version.outputs.TAG }}
          git push origin --tags
          echo "NEW=true" >> $GITHUB_OUTPUT
    outputs:
      new_version: ${{ steps.push-new-tag.outputs.NEW }}

  publish-pypi:
    needs: [bump_version]
    runs-on: ubuntu-latest
    if: |
      (needs.bump_version.result == 'success') &&
      (needs.bump_version.outputs.new_version)

    steps:
      - uses: actions/checkout@v2
      - uses: actions/cache@v2
        id: wheels_cache
        with:
          path: ./wheels
          key: wheels-${{ github.sha }}

      - name: Setup Python
        uses: actions/setup-python@v1
        with:
          python-version: 3.8

      - name: Install Twine
        run: |
          python -m pip install --upgrade pip
          python -m pip install --upgrade setuptools
          python -m pip install --upgrade \
           toml \
           wheel \
           twine
          python -m pip freeze

      - name: Upload to PyPI
        env:
          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
          TWINE_USERNAME: __token__

        run: |
          ls wheels/clean/
          twine upload --non-interactive --skip-existing wheels/clean/*

  publish-s3:
    needs: [bump_version]
    runs-on: ubuntu-latest
    if: |
      (needs.bump_version.result == 'success') &&
      (needs.bump_version.outputs.new_version)

    steps:
      - uses: actions/checkout@v2
      - uses: actions/cache@v2
        id: wheels_cache
        with:
          path: ./wheels
          key: wheels-${{ github.sha }}

      - name: Prepare for upload to S3
        run: |
          mkdir -p ./pips
          ./scripts/mk-pip-tree.sh ./wheels/clean/ ./pips
          find ./pips -type f

      - name: Upload to S3
        run: |
          aws s3 ls "${S3_DST}"
          aws s3 sync ./pips/ "${S3_DST}"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: 'ap-southeast-2'
          AWS_REGION: 'ap-southeast-2'
          S3_DST: 's3://datacube-core-deployment/'
